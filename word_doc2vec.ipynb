{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word_doc2vec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPIN8xXlYyuTrmK4KRyx2Pm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shashank-m/covid_mining_papers/blob/master/word_doc2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkjIIK9BSPHw",
        "colab_type": "text"
      },
      "source": [
        "### Imports and setting up files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfkX688ax5ll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import codecs\n",
        "from tqdm import tqdm\n",
        "import spacy\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vQSWFbzFq8s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5c611b59-d902-43dc-b1db-69f39c91effd"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIgG-tkXu0W2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5845569f-e3f1-4801-ccf1-2b15069974d2"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f37274e3ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFUYtfQ2vWvm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa25270e-f6b0-470a-ee6c-8f7e83e5d81c"
      },
      "source": [
        "\n",
        "is_cuda = torch.cuda.is_available()\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU not available, CPU used\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPmdPOarxzpl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b1984a05-be52-444e-f6c7-f4eb0c9d43cf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GStG0DA1Mr-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "filenames=os.listdir(\"/content/drive/My Drive/covid_nlp/2020-03-13/biorxiv_medrxiv/biorxiv_medrxiv\")\n",
        "biorxiv=\"/content/drive/My Drive/covid_nlp/2020-03-13/biorxiv_medrxiv/biorxiv_medrxiv/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LM5Ha1sRScR",
        "colab_type": "text"
      },
      "source": [
        "## ***Preprocessing of abstract***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RQ02m2Z-Q8vp",
        "colab": {}
      },
      "source": [
        "all_files=[json.load(open(biorxiv+filename, 'rb')) for filename in filenames]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBXKyGftMrtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f=all_files[32]\n",
        "abstract=''\n",
        "for dic in f['abstract']:\n",
        "  abstract+=dic['text']\n",
        "  abstract+='\\n'\n",
        "abstract=abstract.lower() # converts all alphabets to lower case."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZAI-MrH-ezyv",
        "colab": {}
      },
      "source": [
        "def preprocess(abstract):\n",
        "  abstract=re.sub(r'[,-?<>:!_+=#$()%^{}|~@;\\'.\"*&[\\]]',' ',abstract) #remove punctuation.\n",
        "  abstract=re.sub(r'\\d+',' ',abstract) # remove digits.\n",
        "  abstract=re.sub(r'\\s+',' ',abstract).strip() # replace multiple white spaces with single whiite space.\n",
        "  return abstract"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoA9vczYdCGF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55150239-0bf4-429f-cf9e-cb0901bafba4"
      },
      "source": [
        "abstract=preprocess(abstract)\n",
        "len(abstract)"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5602"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXA_8NeXgAAo",
        "colab_type": "text"
      },
      "source": [
        "### **Create train and test data for CBOW model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ofbasEsgw7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNs-8xDUdCDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_tokens=re.findall(r'\\S+',abstract)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1erukxkLf-74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "penta_gram=ngrams(all_tokens,5)\n",
        "for window in penta_gram:\n",
        "  window=list(window)\n",
        "  test_word=window[2]\n",
        "  train_words=window[:2]+window[3:]\n",
        "  train_data.append((train_words,test_word))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3RRe-lsMUco",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d825059-8677-4a75-8560-57f9022ebf56"
      },
      "source": [
        "\n",
        "vocab=set(all_tokens)\n",
        "vocab_size=len(set(all_tokens))\n",
        "word_to_idx={}\n",
        "for i,word in enumerate(vocab):\n",
        "  word_to_idx[word]=i\n",
        "vocab_size  "
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "380"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3BhJo867ytk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24448145-95fe-4b76-912b-7c3e43cabf80"
      },
      "source": [
        "context_data=[]\n",
        "target_data=[]\n",
        "for context,target in train_data:\n",
        "  inputs=torch.LongTensor([word_to_idx[word] for word in context]).view(1,-1) \n",
        "  target_vector=torch.LongTensor([word_to_idx[target]])\n",
        "  context_data.append(inputs)\n",
        "  target_data.append(target_vector)\n",
        "len(target_data)"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "834"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doiANoKt9Kqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=torch.cat(context_data,0) # put all training_data into a single tensor so that it can be batched by Dataloader."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d55HfFViAMmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_label=torch.cat(target_data,0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liGM4_aPBJIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=32\n",
        "training=TensorDataset(X_train,X_train_label)\n",
        "train_loader=DataLoader(training,batch_size=batch_size,drop_last=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pLSxnUHRtSF",
        "colab_type": "text"
      },
      "source": [
        "### CBOW model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q6EcYdVNy1o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "11dbb489-0a92-415d-f3a7-0692433e5d70"
      },
      "source": [
        "class cbow(nn.Module):\n",
        "  def __init__(self,vocab_size,embed_dim,context,hidden_dim,batch_size):\n",
        "    super(cbow,self).__init__()\n",
        "    self.bs=batch_size\n",
        "    self.c=context\n",
        "    self.embeddings=nn.Embedding(vocab_size,embed_dim)\n",
        "    self.linear1=nn.Linear(embed_dim,hidden_dim)\n",
        "    self.linear2=nn.Linear(hidden_dim,vocab_size)\n",
        "    \n",
        "  def forward(self,inputs):\n",
        "    # if inputs.shape[0]==self.bs:\n",
        "      embeds=self.embeddings(inputs)\n",
        "      a_1=F.relu(self.linear1(embeds).sum(axis=1)/self.c)\n",
        "      out=self.linear2(a_1)\n",
        "      return out\n",
        "\n",
        "embed_dim=300\n",
        "model=cbow(vocab_size,embed_dim,4,50,batch_size)\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "lr=1e-3\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "model.state_dict"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.state_dict of cbow(\n",
              "  (embeddings): Embedding(380, 300)\n",
              "  (linear1): Linear(in_features=300, out_features=50, bias=True)\n",
              "  (linear2): Linear(in_features=50, out_features=380, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q7-Amdneu2v",
        "colab_type": "text"
      },
      "source": [
        "**Note that here training data is generated from only one sentence.We run the cbow model over 5 epochs and it looks like the model is learning something as the loss decreases every epoch. If we can overfit on this small data that means out training process works. We just need to collect more training data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-sN2ccJYreu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "8313141c-4a2d-47e1-b042-1ab8ed630711"
      },
      "source": [
        "epochs=20\n",
        "for j in range(epochs):\n",
        "  for i,(x,y) in enumerate(train_loader):\n",
        "    model.zero_grad()\n",
        "    out=model(x)\n",
        "\n",
        "    loss=criterion(out,y)\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "  print('After epoch {},loss={}'.format(j+1,loss))    "
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After epoch 1,loss=5.886552810668945\n",
            "After epoch 2,loss=5.637553691864014\n",
            "After epoch 3,loss=5.256957054138184\n",
            "After epoch 4,loss=4.88704776763916\n",
            "After epoch 5,loss=4.591850757598877\n",
            "After epoch 6,loss=4.321923732757568\n",
            "After epoch 7,loss=4.048618316650391\n",
            "After epoch 8,loss=3.7620370388031006\n",
            "After epoch 9,loss=3.451620101928711\n",
            "After epoch 10,loss=3.1249191761016846\n",
            "After epoch 11,loss=2.7781734466552734\n",
            "After epoch 12,loss=2.4235076904296875\n",
            "After epoch 13,loss=2.075063467025757\n",
            "After epoch 14,loss=1.7503348588943481\n",
            "After epoch 15,loss=1.450291633605957\n",
            "After epoch 16,loss=1.1923034191131592\n",
            "After epoch 17,loss=0.9794098138809204\n",
            "After epoch 18,loss=0.8130475878715515\n",
            "After epoch 19,loss=0.6809931993484497\n",
            "After epoch 20,loss=0.5742940902709961\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdDMH16Sl8HE",
        "colab_type": "text"
      },
      "source": [
        "**As we can see above, our tarin loss almost comes down to zero. This shows the learning process is not an issue. Time to collect more trainig data.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUP2eqPYlFwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}